{"cells":[{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["import torch\n","from torch import tensor\n","from math import sqrt\n","from torch.nn.functional import softmax\n","\n","def par_attention(queries: tensor, keys: tensor, values: tensor, dim: int) -> tensor:\n","    # a batch of 2d matrixes is produced: 3d\n","    raw_weights = torch.bmm(queries, keys.transpose(1, 2))\n","\n","    mask = torch.tril(torch.ones_like(raw_weights), diagonal=0)\n","    raw_weights = raw_weights.masked_fill(mask == 0, float('-inf'))\n","    # ^ still a batch of matrices\n","    # print(f\"raw_weights.shape:{raw_weights.shape}\\nraw_weights: {raw_weights}\")\n","\n","    scale_factor = sqrt(float(dim))\n","    scaled_weights = softmax(raw_weights / scale_factor, dim=2) \n","    # ^ still same structure\n","\n","    # I add a bonus dimension. why tf did I do this...?\n","    reshaped_scaled_weights = scaled_weights.view(scaled_weights.shape[0], scaled_weights.shape[1], scaled_weights.shape[2], 1)\n","    # I do the same thing to the original values 3d tensor, making that 4d too. But I add the extra dimension at the start\n","    reshaped_values = values.view(values.shape[0], values.shape[1], 1, values.shape[2])\n","\n","    # The goal now is: for each value in each row of weights in scaled_weights, I multiply a value row by that scalar.\n","    print(f\"reshaped_scaled_weights:{reshaped_scaled_weights.shape}\\nreshaped_values:{reshaped_values.shape}\")\n","    scaled_values = reshaped_scaled_weights * reshaped_values\n","\n","    contextualized_values = torch.sum(scaled_values, 2)\n","    return contextualized_values"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reshaped_scaled_weights:torch.Size([1, 2, 2, 1])\n","reshaped_values:torch.Size([1, 2, 1, 2])\n"]},{"data":{"text/plain":["tensor([[0., 5.],\n","        [3., 2.]])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["Q = tensor([[1, 3], [1, 1]]).float().unsqueeze(0)\n","K = tensor([[2, 1], [3, 5]]).float().unsqueeze(0)\n","V = tensor([[0, 5], [3, 2]]).float().unsqueeze(0)\n","d = 2\n","output = par_attention(Q, K, V, d)\n","output[0]"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["reshaped_scaled_weights:torch.Size([3, 2, 2, 1])\n","reshaped_values:torch.Size([3, 2, 1, 2])\n"]},{"data":{"text/plain":["tensor([[[0., 5.],\n","         [3., 2.]],\n","\n","        [[0., 5.],\n","         [3., 2.]],\n","\n","        [[0., 5.],\n","         [3., 2.]]])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["Q_batch = torch.zeros([3, 2, 2]).float()\n","Q_batch[0] = Q\n","Q_batch[1] = Q\n","Q_batch[2] = Q\n","K_batch = torch.zeros([3, 2, 2]).float()\n","K_batch[0] = K\n","K_batch[1] = K\n","K_batch[2] = K\n","V_batch = torch.zeros([3, 2, 2]).float()\n","V_batch[0] = V\n","V_batch[1] = V\n","V_batch[2] = V\n","d = 2\n","\n","par_attention(Q_batch, K_batch, V_batch, d)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
