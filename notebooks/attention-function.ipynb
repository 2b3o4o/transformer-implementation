{"cells":[{"cell_type":"markdown","metadata":{},"source":["Ok, so in this file I'm going to implement an attention function. What is an attention function?\n","- It helps us find the contextualized meaning of a certain word/token.\n","- Input: One query vector, many key vectors, equally many value vectors.\n","- Output: New, more richly contextualized value vector corresponding to the word we got a query vector for.\n","Also, in practice it's a good idea to compute many attention functions at once to take advantage of matrix multiplication speedup. I'll worry about that after I get the minimal version of the function working."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","from torch import tensor\n","from torch.nn.functional import softmax\n","from math import sqrt"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# I assume all rows have the same dimension, which is provided in dim\n","# keys, values are assumed to be structured such that each key/value is a row.\n","# Of course, there must also be an equal number of keys and values, so those matrices must have equal dimensions\n","def attention(query: tensor, keys: tensor, values: tensor, dim: int) -> tensor:\n","    # query = query.view(1, -1)\n","    raw_weights = query @ keys.T\n","    scale_factor = sqrt(dim)\n","    scaled_weights = softmax(raw_weights / scale_factor, dim=0)\n","\n","    scaled_values = scaled_weights.view(-1, 1) * values\n","    contextualized_value = torch.sum(scaled_values, 0)\n","\n","    return contextualized_value\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Query tensor: tensor([0.2431, 0.6326, 0.1152, 0.8423, 0.6666])\n","Keys tensor: tensor([[0.7123, 0.1488, 0.2927, 0.0413, 0.1383],\n","        [0.1572, 0.0147, 0.4294, 0.6719, 0.2709],\n","        [0.2583, 0.0736, 0.8304, 0.6375, 0.5369],\n","        [0.5114, 0.0867, 0.6610, 0.1255, 0.9041]])\n","Values tensor: tensor([[0.4356, 0.9212, 0.4823, 0.4276, 0.9394],\n","        [0.5483, 0.2654, 0.7928, 0.3881, 0.2428],\n","        [0.9190, 0.8477, 0.3635, 0.2128, 0.9751],\n","        [0.0507, 0.0645, 0.1399, 0.3570, 0.6768]])\n","Result: tensor([0.4976, 0.5113, 0.4364, 0.3390, 0.7064])\n"]}],"source":["# Define the dimension\n","dim = 5\n","\n","# Generate random tensors for testing\n","query = torch.rand(dim)\n","keys = torch.rand(4, dim)  # 4 keys, each of dimension 'dim'\n","values = torch.rand(4, dim)  # 4 values, each of dimension 'dim'\n","\n","# Call the attention function\n","result = attention(query, keys, values, dim)\n","\n","# Print the tensors and result\n","print(\"Query tensor:\", query)\n","print(\"Keys tensor:\", keys)\n","print(\"Values tensor:\", values)\n","print(\"Result:\", result)"]},{"cell_type":"markdown","metadata":{},"source":["This is not a meaningful way of testing my code lol, but I'm in a hurry so I'll leave this largely untested and reconsider testing later if I suspect a problem in this component. Next is the parallelized attention function, which takes many queries at once instead of just one."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# I assume all rows have the same dimension, which is provided in dim.\n","# queries, keys, values are assumed to be structured such that each query/key/value is a row.\n","def attention(queries: tensor, keys: tensor, values: tensor, dim: int) -> tensor:\n","    breakpoint()\n","    raw_weights = queries @ keys.T\n","    scale_factor = sqrt(dim)\n","    scaled_weights = softmax(raw_weights / scale_factor, dim=1)\n","\n","    # now scaled weights is a matrix where each row represents the scaled weights produced based on a given query.\n","    # meanwhile values just has a value vector on each row.\n","\n","    reshaped_scaled_weights = scaled_weights.view(scaled_weights.shape[0], scaled_weights.shape[1], 1)\n","    reshaped_values = values.view(1, values.shape[0], values.shape[1])\n","\n","    scaled_values = reshaped_scaled_weights * reshaped_values\n","\n","    contextualized_values = torch.sum(scaled_values, 1)\n","    return contextualized_values\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Queries: tensor([[0.5801, 0.4604, 0.9046],\n","        [0.3663, 0.0597, 0.2056],\n","        [0.0462, 0.5163, 0.8533],\n","        [0.4250, 0.6046, 0.0285]])\n","Keys: tensor([[0.3544, 0.9319, 0.0046],\n","        [0.1784, 0.3313, 0.1533],\n","        [0.8533, 0.4826, 0.3342],\n","        [0.7300, 0.0827, 0.6533],\n","        [0.7321, 0.9282, 0.1344]])\n","Values: tensor([[0.4662, 0.5212, 0.7306],\n","        [0.5503, 0.7979, 0.5419],\n","        [0.7162, 0.7844, 0.0497],\n","        [0.6775, 0.2824, 0.1225],\n","        [0.0245, 0.2821, 0.8845]])\n","Resulting contextualized values:\n","tensor([[0.4871, 0.5167, 0.4452],\n","        [0.4886, 0.5270, 0.4537],\n","        [0.4837, 0.5226, 0.4617],\n","        [0.4657, 0.5237, 0.4865]])\n"]}],"source":["# %%debug\n","queries = torch.rand((4, 3))  # 4 queries, each of dimension 3\n","print(f\"Queries: {queries}\")\n","keys = torch.rand((5, 3))     # 5 keys, each of dimension 3\n","print(f\"Keys: {keys}\")\n","values = torch.rand((5, 3))   # 5 values, each of dimension 3\n","print(f\"Values: {values}\")\n","\n","# Call the attention function\n","result = attention(queries, keys, values, 3)\n","\n","print(\"Resulting contextualized values:\")\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["Something seems to be off with this one, as the output values all seem to be very similar. I think it's time to move on, so I'll plan to use the non parallelized version and fix this one later if necessary."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
