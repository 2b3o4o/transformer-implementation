{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","from torch import tensor, sin, cos\n","from math import sqrt\n","from torch.nn.functional import softmax\n","import spacy\n","from torchtext.vocab import GloVe"]},{"cell_type":"markdown","metadata":{},"source":["Set up our tokenizer and 3rd party embedding library"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["glove = GloVe(dim=300)\n","tokenizer = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"markdown","metadata":{},"source":["Define key helper functions used throughout training and inference"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def par_attention(queries: tensor, keys: tensor, values: tensor, dim: int) -> tensor:\n","    raw_weights = torch.bmm(queries, keys.transpose(1, 2))\n","\n","    mask = torch.tril(torch.ones_like(raw_weights), diagonal=0)\n","    raw_weights = raw_weights.masked_fill(mask == 0, float('-inf'))\n","    # print(f\"raw_weights.shape:{raw_weights.shape}\\nraw_weights: {raw_weights}\")\n","\n","    scale_factor = sqrt(dim)\n","    scaled_weights = softmax(raw_weights / scale_factor, dim=2)\n","    # print(f\"scaled_weights.shape:{scaled_weights.shape}\\nscaled_weights: {scaled_weights}\")\n","\n","    # now scaled weights is a matrix where each row represents the scaled weights produced based on a given query.\n","    # meanwhile values just has a value vector on each row.\n","\n","    reshaped_scaled_weights = scaled_weights.view(scaled_weights.shape[0], scaled_weights.shape[1], scaled_weights.shape[2], 1)\n","    reshaped_values = values.view(values.shape[0], values.shape[1], 1, values.shape[2])\n","\n","    scaled_values = reshaped_scaled_weights * reshaped_values\n","\n","    contextualized_values = torch.sum(scaled_values, 2)\n","    return contextualized_values\n","\n","def build_dictionary(file_path) -> (dict, dict):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        content = file.read()\n","    \n","    tokens = tokenizer(content)\n","    unique_words = set()\n","    for token in tokens:\n","        unique_words.add(str(token))\n","    word_to_id = {str(word): i for i, word in enumerate(unique_words)}\n","    id_to_word = {i: str(word) for i, word in enumerate(unique_words)}\n","\n","    return word_to_id, id_to_word\n","\n","def positional_embedding(word, pos) -> tensor:\n","    model_dims = 300\n","\n","    positional_encoding = torch.tensor([0.0] * model_dims)\n","    for i in range(0, model_dims // 2):\n","        positional_encoding[2 * i] = sin(torch.tensor(pos / (10000 ** (2 * i / model_dims))))\n","        positional_encoding[2 * i + 1] = cos(torch.tensor(pos / (10000 ** (2 * i / model_dims))))\n","\n","    embedding = glove[word]\n","    embedding += positional_encoding\n","    return embedding\n","\n","def encode_input_string(str, context_len) -> tensor:\n","    tokenizer = spacy.load(\"en_core_web_sm\")\n","    tokens = tokenizer(str)\n","\n","    output = torch.zeros(size=[context_len, 300])\n","    for i, token in enumerate(tokens):\n","        output[i] = positional_embedding(token.text, i)\n","\n","    return output\n","\n","def encode_input_tokens(tokens, context_len) -> tensor:\n","    output = torch.zeros(size=[context_len, 300])\n","    for i, token in enumerate(tokens):\n","        output[i] = positional_embedding(token.text, i)\n","\n","    return output\n","\n","# slice_offset is the number of tokens separating the start of one slice from the start of the previous.\n","# slice_offset == slice_length means no overlap, slice_offset == 1 means maximum overlap.\n","def slice_text(text: str, slice_length, slice_offset) -> [spacy.tokens.span.Span]:\n","    slices = []\n","    tokens = tokenizer(text)\n","\n","    for i in range(0, len(tokens), slice_offset):\n","        slices.append(tokens[i:i+slice_length])\n","    return slices"]},{"cell_type":"markdown","metadata":{},"source":["Define the architecture of the model, including all subcomponents"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","class AttentionHead(nn.Module):\n","    # For simplicity, I assume query, key, and value vectors have the same dimensionality\n","    def __init__(self, model_dim, vectors_dim):\n","        super().__init__()\n","        self.model_dim = model_dim\n","        self.vectors_dim = vectors_dim\n","        self.Q_proj = nn.Linear(model_dim, vectors_dim, bias=False)\n","        self.K_proj = nn.Linear(model_dim, vectors_dim, bias=False)\n","        self.V_proj = nn.Linear(model_dim, vectors_dim, bias=False)\n","\n","    def forward(self, x):\n","        # each row of x is a vector representing the meaning of the token at the corresponding position with whatever context we've attained so far.\n","        Q = self.Q_proj(x)\n","        K = self.K_proj(x)\n","        V = self.V_proj(x)\n","        # print(\"Shape of Q matrix: \", Q.shape)\n","        # print(\"Shape of K matrix: \", K.shape)\n","        # print(\"Shape of V matrix: \", V.shape)\n","        output = par_attention(Q, K, V, self.vectors_dim)\n","        return output\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, model_dim, num_heads):\n","        super().__init__()\n","        self.att_heads = nn.ModuleList([AttentionHead(model_dim, model_dim // num_heads) for _ in range(num_heads)])\n","        self.proj = nn.Linear(model_dim, model_dim, bias=False)\n","\n","    def forward(self, x):\n","        head_outputs = [head(x) for head in self.att_heads]\n","        x = torch.concat(head_outputs, dim=2)\n","        x = self.proj(x)\n","        return x\n","        \n","class TransformerLayer(nn.Module):\n","    def __init__(self, model_dim, num_heads, ff_hidden_dim, context_len):\n","        super().__init__()\n","        self.attention_block = MultiHeadAttention(model_dim, num_heads)\n","        self.norm1 = nn.LayerNorm(normalized_shape=[context_len, model_dim])\n","        self.ff1 = nn.Linear(model_dim, ff_hidden_dim)\n","        self.ff_relu = nn.ReLU()\n","        self.ff2 = nn.Linear(ff_hidden_dim, model_dim)\n","        self.norm2 = nn.LayerNorm(normalized_shape=[context_len, model_dim])\n","\n","    def forward(self, x):\n","        x_res = x\n","        x = self.attention_block(x)\n","        x += x_res\n","        x = self.norm1(x)\n","\n","        x_res = x\n","        x = self.ff1(x)\n","        x = self.ff_relu(x)\n","        x = self.ff2(x)\n","        x += x_res\n","        x = self.norm2(x)\n","\n","        return x\n","\n","class TransformerNetwork(nn.Module):\n","    def __init__(self, num_layers, model_dim, att_heads, ff_hidden_dim, context_len, output_dict_size):\n","        super().__init__()\n","        # self.trans_layers = nn.ModuleList([TransformerLayer(model_dim, att_heads, ff_hidden_dim, context_len) for _ in range(num_layers)])\n","        self.word_predictor = nn.Linear(model_dim * context_len, output_dict_size)\n","        print(f\"word_predictor input dimension: {model_dim * context_len}\\noutput dimension: {output_dict_size}\")\n","\n","    def forward(self, x):\n","        print(f\"Received x of shape: {x.shape}\")\n","        # for layer in self.trans_layers:\n","        #     x = layer.forward(x)\n","        x = x.view(x.shape[0], -1)\n","        print(f\"Reshaped x to shape: {x.shape}\")\n","        x = self.word_predictor(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["Build a dictionary based on a file. This is used to limit the subset of tokens that the model is allowed to output, and by extension to reduce the size of the model. The limitation of this is that any time you want a new dictionary/set of allowed outputs you need to rebuild and retrain the model. This can obviously be improved on later, but for now I think it's a good idea to use it to train a bit faster."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["word_to_id, id_to_word = build_dictionary('../data/much_ado_about_nothing_gut.txt')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# This approach kinda sucks ay? Cause it assumes I already know what the last token is... Whatever, will iterate on this lol\n","def encode_inputs(input_list, context_len) -> tensor:\n","    output = torch.zeros(size=[len(input_list), context_len, 300])\n","    for i, input in enumerate(input_list):\n","        output[i] = encode_input_string(input, context_len)\n","    return output\n","\n","# def encode_outputs(output_tokens: [str]) -> tensor:\n","#     output_cats = torch.zeros(size=[len(output_tokens)]).long()\n","#     for i, token in enumerate(output_tokens):\n","#         output_cats[i] = word_to_id[token]\n","#     return output_cats"]},{"cell_type":"markdown","metadata":{},"source":["Tools to quickly build a dataset that can be fed into the model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class CompletionDataset(Dataset):\n","    def __init__(self, features, labels):\n","        self.features = features\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return self.features.shape[0]\n","\n","    def __getitem__(self, index):\n","        return self.features[index], self.labels[index]\n","\n","# Note: slices include features + label. So if you have context length 256, you can set slice length 257 and be fine.\n","def build_dataset_from_text(text: str, context_len, slice_length, slice_offset, word_to_id_dict, print_slices) -> CompletionDataset:    \n","    slices = slice_text(text, slice_length, slice_offset)\n","\n","    if print_slices:\n","        for i, slice in enumerate(slices):\n","            print(f\"Slice {i}:\")\n","            print(slice)\n","            print(\"\")\n","\n","    features = torch.zeros(size=[len(slices), context_len, 300])\n","    labels = torch.zeros(size=[len(slices)]).long()\n","    for i, slice in enumerate(slices):\n","        last_token = slice[-1]\n","        labels[i] = word_to_id_dict[str(last_token)]\n","        encoding = encode_input_tokens(slice[:-1], context_len)\n","        features[i] = encoding\n","    \n","    dataset = CompletionDataset(features, labels)\n","    return dataset\n","\n","def build_dataset_from_file(filename, context_len, slice_length, slice_offset, word_to_id_dict, print_slices):\n","    with open(filename, 'r', encoding='utf-8') as file:\n","        content = file.read()\n","    return build_dataset_from_text(content, context_len, slice_length, slice_offset, word_to_id_dict, print_slices)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize model. Output dict size is the size of the final layer."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["word_predictor input dimension: 2400\n","output dimension: 3392\n","dictionary_len: 3392\n"]}],"source":["dictionary_len = len(id_to_word)\n","context_len = 8\n","model = TransformerNetwork(num_layers=2, model_dim=300, att_heads=6, ff_hidden_dim=1200, context_len=context_len, output_dict_size=dictionary_len)\n","print(f\"dictionary_len: {dictionary_len}\")"]},{"cell_type":"markdown","metadata":{},"source":["Actually build the dataset:"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["max_slice_len = context_len + 1\n","dataset = build_dataset_from_file('../data/much_ado_about_nothing_gut.txt', context_len, max_slice_len, 1, word_to_id, False)\n","# dataset += build_dataset_from_file('../data/much_ado_about_nothing_gut.txt', context_len, max_slice_len // 4, max_slice_len * 2, word_to_id, False)\n","# dataset = build_dataset_from_file('../data/much_ado_about_nothing_gut.txt', context_len, max_slice_len, max_slice_len * 2, word_to_id, False)\n"]},{"cell_type":"markdown","metadata":{},"source":["Define model hyperparameters and set up data loader."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","loss_func = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","\n","# sub_dataset = dataset[:32]\n","train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=False)\n","# val_loader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def train_one_epoch(do_validation: bool):\n","    model.train(True)\n","    torch.set_printoptions(profile=\"short\")\n","    batches = 0\n","    avg_loss = 0\n","    for step, (features, labels) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        preds = model(features)\n","        print(f\"preds:{preds}\\nlabels:{labels}\")\n","        loss = loss_func(preds, labels)\n","        loss.backward()\n","\n","        if step % 10 == 0:  # Print every 10 batches\n","            for name, param in model.named_parameters():\n","                if param.requires_grad:\n","                    print(f\"Gradient data for {name}:\", param.grad)\n","                    print(f\"Checking if gradients are fully zeroed: {torch.all(param.grad == 0.0).item()}\")\n","                    print(f\"Shape: {param.grad.shape}\")\n","                    print(f\"Mean: {param.grad.mean()}\")\n","                    print(f\"Std: {param.grad.std()}\")\n","                    print(f\"Min: {param.grad.min()}\")\n","                    print(f\"Max: {param.grad.max()}\")\n","\n","        optimizer.step()\n","\n","        print(f\"Loss on batch {step}: {loss}\")\n","\n","        avg_loss += loss\n","        batches = step + 1\n","        break\n","    \n","    avg_loss = avg_loss / batches\n","    print(f\"Average loss for training batches in this epoch: {avg_loss}\")\n","\n","    if do_validation:\n","        model.train(False)\n","        batches = 0\n","        avg_loss = 0\n","        for step, (features, labels) in enumerate(val_loader):\n","            preds = model(features)\n","            # print(f\"preds:{preds}\\nlabels:{labels}\")\n","            loss = loss_func(preds, labels)\n","            \n","            print(f\"Loss on step {step}: {loss}\")\n","\n","            avg_loss += loss\n","            batches = step + 1\n","\n","        avg_loss = avg_loss / batches\n","        print(f\"Average loss for validation batches in this epoch: {avg_loss}\")\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Received x of shape: torch.Size([32, 64, 300])\n","Reshaped x to shape: torch.Size([32, 19200])\n","preds:tensor([[-0.37,  0.23,  ..., -0.39,  0.32],\n","        [-3.17, -0.43,  ..., -1.14,  1.83],\n","        ...,\n","        [12.15,  0.33,  ..., -3.39,  5.63],\n","        [-9.80,  1.16,  ..., -5.63,  7.86]], grad_fn=<AddmmBackward0>)\n","labels:tensor([2436, 1859, 3119, 2577, 2385,  710,  406, 3086, 2088,  163, 1048,  869,\n","        2392, 1223, 3065, 1241, 1494, 2944, 1241,  860,  601, 3176, 3025,  942,\n","         163,  894, 3235, 2186, 1241,  163, 2186, 3381])\n","Gradient data for word_predictor.weight: tensor([[-1.11e-42,  1.98e-42,  ...,  7.44e-43,  3.57e-42],\n","        [-2.04e-42,  3.62e-42,  ...,  1.36e-42,  6.53e-42],\n","        ...,\n","        [-1.10e-42,  1.95e-42,  ...,  7.31e-43,  3.51e-42],\n","        [-2.22e-42,  3.94e-42,  ...,  1.48e-42,  7.09e-42]])\n","Checking if gradients are fully zeroed: False\n","Shape: torch.Size([3392, 19200])\n","Mean: -4.685899563337814e-13\n","Std: 0.0010360482847318053\n","Min: -0.23651960492134094\n","Max: 0.21072646975517273\n","Gradient data for word_predictor.bias: tensor([3.73e-42, 6.84e-42,  ..., 3.68e-42, 7.43e-42])\n","Checking if gradients are fully zeroed: False\n","Shape: torch.Size([3392])\n","Mean: 1.742593835072151e-13\n","Std: 0.0007207189337350428\n","Min: -0.03125\n","Max: 0.027842098847031593\n","Loss on batch 0: 0.5689756274223328\n","Average loss for training batches in this epoch: 0.5689756274223328\n"]}],"source":["train_one_epoch(False)\n","# train_one_epoch()\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def infer_completion(input_text: str, context_len):\n","    encoded_input = encode_inputs([input_text], context_len)\n","    \n","    model.train(False)\n","    pred = model(encoded_input)\n","    return id_to_word[torch.argmax(softmax(pred, dim=1), dim=1).item()]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Received x of shape: torch.Size([1, 64, 300])\n","Reshaped x to shape: torch.Size([1, 19200])\n"]},{"data":{"text/plain":["'twas'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["infer_completion(\"Well, I am glad that all things sort so well Pedro\", context_len)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'param' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\src\\alignment-study\\transformer-implementation\\notebooks\\train-2.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/src/alignment-study/transformer-implementation/notebooks/train-2.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m param\u001b[39m.\u001b[39mgrad\n","\u001b[1;31mNameError\u001b[0m: name 'param' is not defined"]}],"source":["param.grad"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
